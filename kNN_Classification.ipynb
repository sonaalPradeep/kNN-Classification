{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the kNN algorithm for classification\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 About the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest neighbours (kNN) algorithm is a very simple, easy to understand and easy to implement algorithm. It is an algorithm wherein the <b>output is dependent on the <i>k</i> closest neighbors</b> of a given dataset. kNN can be used for either classification or regression.\n",
    "\n",
    "* In the case of classification, the aim is to find the class of a given input data; the output being the class label it belongs to, which is the most common class label amongst <i>k</i> of its nearest neighbours.\n",
    "* In the case of regression, the output is the average value of an attribute to the <i>k</i> nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lazy Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kNN algorithm is sometimes reffered as a \"Lazy Learning\" algorithm, as oppose to the \"Eager Learning\" algorithm. The lazy learning method is a method in which the training set is only memorized and no descriminatory functions are involved. The eager learning method is thus the method wherein the model tries to find a generalisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 The dataset\n",
    "### 2.1 About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is \"The Iris dataset\" which is a very common dataset used for training and testing machine learning models. This data is stored in a CSV file of 150 rows. The dataset is used to classify the Iris flower based on 4 attributes:\n",
    "\n",
    "1. Sepal length\n",
    "2. Sepal width\n",
    "3. Petal length\n",
    "4. Petal width\n",
    "\n",
    "Using these attributes, the flower is categorized into one of following class:\n",
    "\n",
    "1. Setosa\n",
    "2. Versicolor\n",
    "3. Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length,sepal_width,petal_length,petal_width,species\r\n",
      "5.1,3.5,1.4,0.2,setosa\r\n",
      "4.9,3.0,1.4,0.2,setosa\r\n",
      "4.7,3.2,1.3,0.2,setosa\r\n",
      "4.6,3.1,1.5,0.2,setosa\r\n",
      "5.0,3.6,1.4,0.2,setosa\r\n",
      "5.4,3.9,1.7,0.4,setosa\r\n",
      "4.6,3.4,1.4,0.3,setosa\r\n",
      "5.0,3.4,1.5,0.2,setosa\r\n",
      "4.4,2.9,1.4,0.2,setosa\r\n"
     ]
    }
   ],
   "source": [
    "! head iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be see that the dataset consists of 5 columns, the last one being the class the flower belongs to. It should also be noted that the first line consists of the column names, which needs to be removed when taking in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the logic\n",
    "\n",
    "### 3.1 Modus operandi\n",
    "\n",
    "To find the label of a given data point, first the distances from that point to all the other points are found out, and the <i>k</i> nearest ones are selected. Another function determines the label by finding out which is the most common label amongst the <i>k</i> selected nearest neighbours.\n",
    "\n",
    "### 3.2 Euclidean and Manhattan distance measures\n",
    "\n",
    "There are many different ways to find the distance between two points. The most commonly used methods are the <b>Euclidean measure</b> and the <b>Manhattan measure</b>.\n",
    "    \n",
    "#### 3.2.1 Euclidean measure\n",
    "\n",
    "The Euclidean measure considers the distance between two points as <b>the length of the straight line</b> passing through both points.\n",
    "\n",
    "![Euclidean Distance from Wikipedia](https://wikimedia.org/api/rest_v1/media/math/render/svg/795b967db2917cdde7c2da2d1ee327eb673276c0)\n",
    "\n",
    "#### 3.2.2 Manhattan measure\n",
    "\n",
    "In the Manhattan measure, the distance between two points is taken as <b>the sum of the absolute difference</b> of the coordinates.\n",
    "\n",
    "![Taxicab geometry from Wikipedia](https://wikimedia.org/api/rest_v1/media/math/render/svg/02436c34fc9562eb170e2e2cfddbb3303075b28e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Importing the required modules\n",
    "The following modules are required to read the CSV file, for math operations and for spliting the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Loading the data\n",
    "\n",
    "The data in the CSV file needs to be loaded into the list. The first line needs to be omitted because it just consists strings of the column names. And since the CSV reader function loads the data as strings, all the numerical data needs to be converted to floats. The loadCSV() function handles all this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV():\n",
    "    data= csv.reader(open(r'iris.csv'))\n",
    "    lines = list(data)\n",
    "    lines = lines[1:]\n",
    "    dataSize = len(lines[0])\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines[i])):\n",
    "            if j == len(lines[i]) - 1:\n",
    "                lines[i][j] = str(lines[i][j])\n",
    "            else:\n",
    "                lines[i][j] = float(lines[i][j])\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Spliting the data into training and testing sets\n",
    "\n",
    "The loaded data needs to be divided into testing and training sets. This partitioning is determined by the 'splitRatio' variable. Generally a ratio of 67:33 training to testing is taken. The data is chosen randomly from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(data, splitRatio = 0.67):\n",
    "    trainSize = int(len(data) * splitRatio)\n",
    "    trainSet = []\n",
    "    testSet = list(data)\n",
    "    \n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(testSet))\n",
    "        trainSet.append(testSet.pop(index))\n",
    "        \n",
    "    random.shuffle(testSet)\n",
    "        \n",
    "    return [trainSet, testSet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Locating the nearest <i>k</i> neighbours\n",
    "\n",
    "The nearest <i>k</i> neighbours can be found out by finding the distance between the input vector and the distance between all the points, and picking the <i>k</i> points with the shortest distance. The distance is found out by using the Euclidean Distance metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDist(inData1, inData2):\n",
    "    distance = 0\n",
    "\n",
    "    for i in range(len(inData1)-1):\n",
    "        distance += math.pow(inData1[i] - inData2[i], 2)\n",
    "        \n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(trainSet, testVector, k = 10):\n",
    "    neighbours = []\n",
    "    \n",
    "    for point in trainSet:\n",
    "        dist = euclideanDist(point, testVector)\n",
    "        neighbours.append([point, dist])\n",
    "        \n",
    "    neighbours.sort(key = lambda x: x[1])\n",
    "    \n",
    "    nearNeighbours = []\n",
    "    for i in range(k):\n",
    "        nearNeighbours.append(neighbours[i][0])\n",
    "        \n",
    "    return nearNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Predictions and Accuracy\n",
    "\n",
    "Predictions are made by looking at the labels of the nearest datasets and labelling the test data point the class which is the most common. The getPredict() function calls the getInstancePredict() for each of the point in the test set, which all gets alloted a label. The list of this label is returned.\n",
    "\n",
    "The accuracy is determined by getting the number of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInstancePredict(nearN, testV):\n",
    "    classCount = {}\n",
    "    \n",
    "    for vertex in nearN:\n",
    "        if vertex[-1] not in classCount:\n",
    "            classCount[vertex[-1]] = 1\n",
    "        else:\n",
    "            classCount[vertex[-1]] += 1\n",
    "            \n",
    "    bestLabel, maxCount = None, -1\n",
    "    \n",
    "    for x in classCount:\n",
    "        if bestLabel == None or classCount[x] > maxCount:\n",
    "            bestLabel = x\n",
    "            maxCount = classCount[x]\n",
    "            \n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredict(trainSet, testSet):\n",
    "    predictions = []\n",
    "    \n",
    "    for testValue in testSet:\n",
    "        nearN = getNeighbours(trainSet, testValue)\n",
    "        predictions.append(getInstancePredict(nearN, testValue))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(pred, testSet):\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(testSet)):\n",
    "        if pred[i] == testSet[i][-1]:\n",
    "            count += 1\n",
    "            \n",
    "    return (count/float(len(testSet)))*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 The main() function\n",
    "\n",
    "The main function encapsulates all of the above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 rows split into 99 training and 51 testing sets\n",
      "Accuracy : 98.039%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data = loadCSV()\n",
    "    trainSet, testSet = splitData(data, 0.66)\n",
    "\n",
    "    print(\"{} rows split into {} training and {} testing sets\".format(len(data), len(trainSet), len(testSet)))\n",
    "\n",
    "    pred = getPredict(trainSet, testSet)\n",
    "    accuracy = getAccuracy(pred, testSet)\n",
    "\n",
    "    print(\"Accuracy : {0:.3f}%\".format(accuracy))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "\n",
    "1. [Youtube : KNN Algorithm using Python](https://www.youtube.com/watch?v=6kZ-OPLNcgE)\n",
    "2. [Wikipedia : k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "3. [Wikipedia : Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)\n",
    "4. [Wikipedia : Manhattan Distance](https://en.wikipedia.org/wiki/Taxicab_geometry)\n",
    "5. [CSV File : The Iris Dataset ](https://gist.github.com/a08a1080b88344b0c8a7.git)\n",
    "5. [Wikipedia : Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
